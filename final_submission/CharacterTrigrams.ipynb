{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import difflib\n",
    "import utils\n",
    "import math\n",
    "import re, string\n",
    "import nltk\n",
    "import itertools\n",
    "from nltk import bigrams\n",
    "from nltk import trigrams\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from gensim import corpora, models, similarities\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import model_selection\n",
    "# from sklearn import preprocessing\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score, log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('train_split.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# simple baseline model...compare words in [Andrea's]\n",
    "\n",
    "def find_similarity(wl1, wl2):\n",
    "    # send 2 word lists to find matching sequence\n",
    "    sm = difflib.SequenceMatcher(None, wl1,wl2)\n",
    "    sm = sm.ratio()\n",
    "    return sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# character tri-gram similarity\n",
    "\n",
    "char_tri_similarity_results = []\n",
    "\n",
    "for id in range(0, len(train)):\n",
    "# test with a smaller loop first\n",
    "# for id in range(0, 20):\n",
    "\n",
    "    q1 = str(train['question1'][id])\n",
    "    q2 = str(train['question2'][id])\n",
    "    \n",
    "    q1 = q1.translate(None, string.punctuation).lower()\n",
    "    q2 = q2.translate(None, string.punctuation).lower()\n",
    "\n",
    "#     q1words = q1.split()\n",
    "#     q2words = q2.split()\n",
    "    \n",
    "#     stop_word=set(stopwords.words('english'))\n",
    "#     q1words=list(word for word in q1words if not word in stop_word)\n",
    "#     q2words=list(word for word in q2words if not word in stop_word)\n",
    "    \n",
    "    char_trigram1 = list(trigrams(q1))\n",
    "    char_trigram2 = list(trigrams(q2))\n",
    "    \n",
    "#     print bigram1, bigram2\n",
    "    \n",
    "    char_tri_similarity_results.append([id, find_similarity(char_trigram1, char_trigram2)])\n",
    "    \n",
    "# print(char_tri_similarity_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def score(actuals, predictions, probability):\n",
    "    score_sm = log_loss(actuals, predictions)\n",
    "    print ('log loss score is: %3f' %(score_sm))\n",
    "    \n",
    "    n_abs = np.where(predictions > probability, 1, 0)\n",
    "    \n",
    "    total_wrong = np.sum(np.not_equal(actuals, n_abs))\n",
    "    print ('number of incorrect predictions is: %3d' %(total_wrong))\n",
    "    total = len(actuals)\n",
    "    correct = total - total_wrong\n",
    "    print ('total: %3d  correct: %3d  accuracy: %3.2f \\n' %(total, correct, 1.0*correct/total))\n",
    "    print classification_report(actuals, n_abs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.621050091737\n",
      "log loss score is: 0.621050\n",
      "number of incorrect predictions is: 134290\n",
      "total: 363861  correct: 229571  accuracy: 0.63 \n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "global name 'classification_report' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-96b61082902f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# print(accuracy_score_sm)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore_char_trigram\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactuals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions_char_trigram\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-459eb87071de>\u001b[0m in \u001b[0;36mscore\u001b[0;34m(actuals, predictions, probability)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mcorrect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtotal_wrong\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'total: %3d  correct: %3d  accuracy: %3.2f \\n'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorrect\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mcorrect\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0;32mprint\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactuals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_abs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: global name 'classification_report' is not defined"
     ]
    }
   ],
   "source": [
    "# character trigram log_loss\n",
    "\n",
    "actuals = np.array(train['is_duplicate'])\n",
    "n_char_trigram_results = np.array(char_tri_similarity_results)\n",
    "predictions_char_trigram = n_char_trigram_results[:,1]\n",
    "score_char_trigram = log_loss(actuals, predictions_char_trigram)\n",
    "# accuracy_score_trigram = accuracy_score(actuals, predictions_trigram)\n",
    "# print(accuracy_score_sm)\n",
    "print(score_char_trigram)\n",
    "score(actuals, predictions_char_trigram, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
